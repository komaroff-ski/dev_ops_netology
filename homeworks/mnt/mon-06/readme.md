## Домашнее задание MON-06, С.Г. Комаров

## Задание 1  

Постмотрем, на основе реального сбоя системы Github в 2018 году.  

1. Краткое описание инцидента (краткая выжимка о инциденте)  

В 22:52 21.10.2022, несколько сервисов на GitHub.com были затронуты сетевым разделом и последующим сбоем базы данных, что привело к несогласованной информации, представленной на нашем веб-сайте. Из соображений предосторожности мы предприняли шаги для обеспечения целостности ваших данных, в том числе приостановили события веб-перехватчиков и другие внутренние системы обработки.

2. Предшествующие события (что произошло перед инцидентом)  

21.10.2022 22:52 в результате регламентных работ на сетевом оборудовании, была потеряна связь между сетевым хабом и ЦОД-ом на восточном побережье США. Время потери связи - 43 сек.

3. Причина инцидента (из-за чего возник инцидент)  

Нарушение согласованности данных в ЦОДах в результате переезда primary-базы из Цода Восток в Цод Запад, после потери сетевой связности.

4. Воздействие (на что повлиял инцидент)  

Дергадация работы сервиса, частичная недоступность некототых функций.

5. Обнаружение (когда и как инцидент был обнаружен)  

21.10.2022 22:54 произошло срабатывание систем мониторинга, сигнализирующих о многочисленных проблемах в работе систем

6. Реакция (кто ответил на инцидент, кто был привлечен, какие каналы коммуникации были задействованы)  

21.10.2022 22:54 Начало работы над инцидентом на уровне группы реагирования
21.10.2022 23:09 установка желтого статура работоспобности сайта
21.10.2022 23:11 Подключился Координатор
21.10.2022 23:13 установка красного статура работоспобности сайта
21.10.2022 23:13 Привлечены эксперты по базам данных
22.10.2022 00:05 Мы обновили наш статус , чтобы проинформировать пользователей о том, что мы собираемся выполнить контролируемый переход на другой ресурс внутренней системы хранения данных.
22.10.2022 07:46 Публикация информациооного письма для пользователей в блоге GitHub

7. Восстановление (описание действий по устранению инцидента и поведение системы)  

1. Ручная остановка заданий, записывающих метаданные о таких вещах, как push-уведомления
2. Восстановление из резерных копий всех затронутых реплик MySQL

8. Таймлайн (последовательное описание ключевых событий инцидента с указанием времени)  
21.10.2022 22:52 Потеря сетевой связности между ЦОдами на восточном (Восток) и западном побережье (Запад), длительность 43 сек.
21.10.2022 22:52 Инициирован процесс передачи топологии кластера в Цод Запад
21.10.2022 22:54 Срабатывание систем мониторинга, многочисленные сбои в работе систем
21.10.2022 23:02 инженеры первой группы реагирования определили, что топологии для многочисленных кластеров БД находятся в неожиданном состоянии. При запросе API Orchestrator отображалась топология репликации БД, содержащая только серверы из западного ЦОД.
21.10.2022 23:07 группа реагирования решила вручную заблокировать внутренние средства развёртывания, чтобы предотвратить внесение дополнительных изменений.
21.10.2022 23:09 установка желтого статура работоспобности сайта
21.10.2022 23:11 к инциденту присоединился Координатор
21.10.2022 23:13 Координатор принимает решение об установке красного уровня работоспособности сайта. К работе над инцидентом привлечены дополнительные инженеры по базам данных.
22.10.2022 00:05 Инженеры из группы реагирования начали разрабатывать план устранения несогласованности данных и запустили процедуры отработки отказа для MySQL. План состоял в том, чтобы восстановить файлы из бэкапа, синхронизировать реплики на обоих сайтах, вернуться к стабильной топологии обслуживания, а затем возобновить обработку заданий в очереди. Мы обновили статус, чтобы сообщить пользователям, что собираемся выполнить управляемую отработку отказа внутренней системы хранения данных.
22.10.2022 00:41 Инициирован процесс восстановления баз данных из резервных копий
22.10.2022 06:51 Несколько кластеров в восточном ЦОД завершили восстановление из резервных копий и начали реплицировать новые данные с Западным побережьем. Это привело к замедлению загрузки страниц, которые выполняли операцию записи через всю страну, но чтение страниц из этих кластеров БД возвращало актуальные результаты, если запрос чтения попадал на только что восстановленную реплику. Другие более крупные кластеры БД продолжали восстанавливаться. Время расчетного восстановления на тот момент было оценено в 2 часа.
22.10.2022 07:46 Публикация информациооного письма для пользователей в блоге GitHub
22.10.2022 11:12 Все первичные базы данных снова переведены в ЦОД Восток. Это привело к значительному росту скорости работы сайта т.к. все основные прикладные сервисы так же расположены в ЦОД Восток. К этому времени стало ясно, что оценка времени полного восстановления была не верной и восстановление займет гораздо большее время.
22.10.2022 13:15 В команде реагирования прошло обсуждение дальнейших действий. Было ясно, что отставание репликации до согласованного состояния увеличивается, а не уменьшается. Ранее мы начали подготовку дополнительных реплик чтения MySQL в общедоступном облаке Восточного побережья. Как только они стали доступны, стало легче распределять поток запросов на чтение между несколькими серверами. Уменьшение средней нагрузки на реплики чтения ускорило догон репликации.
22.10.2022 16:24 После синхронизации реплик мы вернулись к исходной топологии, устранив проблемы задержки и доступности. В рамках сознательного решения о приоритете целостности данных над быстрым исправлением ситуации мы сохранили красный статус сайта, когда начали обрабатывать накопленные данные.
22.10.2022 16:24 На этапе восстановления нужно было сбалансировать возросшую нагрузку, связанную с отставанием, потенциально перегружая наших партнёров по экосистеме уведомлениями и как можно быстрее возвращаясь к стопроцентной работоспособности. В очереди оставалось более пяти миллионов событий хуков и 80 тыс. запросов на построение веб-страниц. Когда мы повторно включили обработку этих данных, то обработали около 200 000 полезных задач с вебхуками, которые превысили внутренний TTL и были отброшены. Узнав об этом, мы остановили обработку и запушили увеличение TTL. Чтобы избежать дальнейшего снижения надёжности наших обновлений статуса, мы оставили статус деградации до тех пор, пока не завершим обработку всего накопившегося объёма данных и не убедимся, что сервисы чётко вернулись к нормальному уровню производительности.
22.10.2022 23:02 Все незавершённые события вебхуков и сборки Pages обработаны, а целостность и правильная работа всех систем подтверждена. Статус сайта обновлён на зелёный.


9. Последующие действия (что нужно предпринять, чтобы инцидент не повторялся) 

Устранение несоответствий данных
Во время нашего восстановления мы захватили двоичные журналы MySQL, содержащие записи, которые мы сделали на нашем основном сайте, но которые не были реплицированы на наш сайт Западного побережья из каждого затронутого кластера. Общее количество операций записи, которые не были воспроизведены на Западном побережье, было относительно небольшим. Например, один из наших самых загруженных кластеров имел 954 записи в затронутом окне. В настоящее время мы проводим анализ этих журналов и определяем, какие записи могут быть автоматически согласованы, а какие потребуют взаимодействия с пользователями. У нас есть несколько команд, занятых этой работой, и наш анализ уже определил категорию записей, которые с тех пор повторялись пользователем и успешно сохранялись. Как указано в этом анализе, наша основная цель — сохранить целостность и точность данных, которые вы храните на GitHub.

Коммуникация
Желая сообщить вам важную информацию во время инцидента, мы сделали несколько публичных оценок времени ремонта на основе скорости обработки невыполненных данных. Оглядываясь назад, наши оценки не учитывали все переменные. Мы приносим извинения за возникшую путаницу и постараемся предоставить более точную информацию в будущем.

Технические инициативы
В ходе этого анализа был выявлен ряд технических инициатив. По мере того, как мы продолжаем проводить обширный внутренний анализ после инцидента, мы рассчитываем определить еще больше работы, которую необходимо выполнить.

Настройте конфигурацию Orchestrator, чтобы предотвратить продвижение основных баз данных через региональные границы. Действия Оркестратора вели себя так, как настроено, несмотря на то, что наш уровень приложений не смог поддержать это изменение топологии. Выборы лидеров в регионе, как правило, безопасны, но внезапная задержка между странами стала основным фактором, способствовавшим этому инциденту. Это было неожиданное поведение системы, учитывая, что ранее мы не видели внутреннего сетевого раздела такого масштаба.
Мы ускорили переход на новый механизм отчетов о состоянии, который предоставит нам более богатый форум для обсуждения активных инцидентов более четким и понятным языком. Хотя во время инцидента многие части GitHub были доступны, мы смогли установить только зеленый, желтый и красный статус. Мы понимаем, что это не дает вам точного представления о том, что работает, а что нет, и в будущем мы будем отображать различные компоненты платформы, чтобы вы знали статус каждой службы.
За несколько недель до этого инцидента мы начали общекорпоративную инженерную инициативу по поддержке обслуживания трафика GitHub из нескольких центров обработки данных в схеме «активный/активный/активный». Целью этого проекта является поддержка резервирования N+1 на уровне объекта. Цель этой работы — допустить полный отказ одного центра обработки данных без воздействия на пользователя. Это серьезное усилие, которое займет некоторое время, но мы считаем, что наличие нескольких сайтов с хорошей связью в одном регионе обеспечивает хороший набор компромиссов. Этот инцидент добавил актуальности инициативе.
Мы займем более активную позицию в проверке наших предположений. GitHub — быстрорастущая компания, и за последнее десятилетие она значительно усложнилась. По мере того, как мы продолжаем расти, становится все труднее фиксировать и передавать исторический контекст компромиссов и решений, принятых новым поколениям Хабберов.

Организационные инициативы
Этот инцидент изменил наше отношение к надежности сайта. Мы узнали, что более строгий операционный контроль или сокращение времени отклика не являются достаточными гарантиями надежности сайта в рамках такой сложной системы служб, как наша. Чтобы поддержать эти усилия, мы также начнем системную практику проверки сценариев сбоев, прежде чем они смогут повлиять на вас. Эта работа потребует будущих инвестиций в инструменты внедрения ошибок и хаос-инжиниринга в GitHub.